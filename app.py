# â”€â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import sys
import streamlit as st
import tensorflow_hub as hub
import numpy as np
import joblib
import os
import mlflow
from mlflow.sklearn import load_model

# â”€â”€â”€ Config TF Hub Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if os.name == "nt":  # Windows (local)
    os.environ["TFHUB_CACHE_DIR"] = r"C:\envs\P5\tfhub_cache"
else:  # Linux (CI/CD, ex: GitHub Actions)
    os.environ["TFHUB_CACHE_DIR"] = "/tmp/tfhub_cache"


# â”€â”€â”€ MLflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mlflow.set_tracking_uri("file:///C:/envs/mlflow_P5/mlruns")

# â”€â”€â”€ Chargements â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.write(f"Environnement Python actif : {os.environ.get('VIRTUAL_ENV', sys.prefix)}")

# 1. USE (Universal Sentence Encoder)
@st.cache_resource
def load_use_model():
    return hub.load("https://tfhub.dev/google/universal-sentence-encoder/4")

use_model = load_use_model()

# 2. Chargement du modÃ¨le de classification depuis MLflow
model_dir = r"C:/envs/P5_models/USE_RL2_model"
model = joblib.load(os.path.join(model_dir, "model.joblib"))

# 3. Chargement du scaler pour normaliser les embeddings
scaler_USE = joblib.load(r"C:\envs\P5\scaler_USE.joblib")

# 4. MultiLabelBinarizer
mlb = joblib.load(r"C:\envs\P5\P5_mlb.pkl")
tags_list = mlb.classes_

# â”€â”€â”€ Interface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("GaÃ«lle_Genvrin_P5_API â€“ Deep Learning + USE")
st.write("Entrez votre question StackOverflow ci-dessous ğŸ‘‡")

question = st.text_area("Question StackOverflow", height=150)

# â”€â”€â”€ PrÃ©diction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_top_5_dl(text):
    embed = use_model([text])  # Liste â†’ Tensor
    embed_scaled = scaler_USE.transform(embed)  # Applique la normalisation

    probs = model.predict_proba(embed_scaled)[0]  # PrÃ©diction des probabilitÃ©s

    tag_probs = list(zip(tags_list, probs))
    tag_probs_sorted = sorted(tag_probs, key=lambda x: x[1], reverse=True)
    
    return tag_probs_sorted[:35]

# â”€â”€â”€ Affichage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("GÃ©nÃ©rer les tags"):
    if not question.strip():
        st.warning("â— Veuillez entrer une question.")
    else:
        top_preds = predict_top_5_dl(question)
        st.subheader("ğŸ·ï¸ Top 35 tags prÃ©dits")
        for tag, p in top_preds:
            st.write(f"**{tag}** â€” {p:.6f}")
